# E-commerce Text Classification

–ü—Ä–æ–µ–∫—Ç –ø–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π —Ç–æ–≤–∞—Ä–æ–≤ —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –∫–æ–º–º–µ—Ä—Ü–∏–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º.

## üìã –ü–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–¥–∞—á–∏

**–¶–µ–ª—å:** –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –º–æ–¥–µ–ª—å –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è.

**–¢–∞—Ä–≥–µ—Ç:** `category` ‚Äî –∫–∞—Ç–µ–≥–æ—Ä–∏—è —Ç–æ–≤–∞—Ä–∞ (4 –∫–ª–∞—Å—Å–∞):
- `Household` ‚Äî —Ç–æ–≤–∞—Ä—ã –¥–ª—è –¥–æ–º–∞ (19 313 –ø—Ä–∏–º–µ—Ä–æ–≤, 38.3%)
- `Books` ‚Äî –∫–Ω–∏–≥–∏ (11 820 –ø—Ä–∏–º–µ—Ä–æ–≤, 23.4%)
- `Electronics` ‚Äî —ç–ª–µ–∫—Ç—Ä–æ–Ω–∏–∫–∞ (10 621 –ø—Ä–∏–º–µ—Ä, 21.1%)
- `Clothing & Accessories` ‚Äî –æ–¥–µ–∂–¥–∞ –∏ –∞–∫—Å–µ—Å—Å—É–∞—Ä—ã (8 671 –ø—Ä–∏–º–µ—Ä, 17.2%)

**–ü—Ä–∏–∑–Ω–∞–∫–∏:**
- `description` ‚Äî —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ (–¥–ª–∏–Ω–∞ –æ—Ç 4 –¥–æ 50 791 —Å–∏–º–≤–æ–ª–æ–≤, –º–µ–¥–∏–∞–Ω–∞ 488 —Å–∏–º–≤–æ–ª–æ–≤)

**–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞:**
- Primary: **F1-macro** (—É—Å—Ä–µ–¥–Ω—ë–Ω–Ω—ã–π F1-score –ø–æ –≤—Å–µ–º –∫–ª–∞—Å—Å–∞–º)
- Secondary: Accuracy, Precision-macro, Recall-macro, F1-weighted

---

## üîç EDA (Exploratory Data Analysis)

### –û—Å–Ω–æ–≤–Ω—ã–µ –≤—ã–≤–æ–¥—ã –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö

1. **–î–∏—Å–±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤:**
   - –ö–ª–∞—Å—Å—ã —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –Ω–µ—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ: –æ—Ç 17% –¥–æ 38%
   - –¢—Ä–µ–±—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø—Ä–∏ —Ä–∞–∑–±–∏–µ–Ω–∏–∏ –∏ –º–µ—Ç—Ä–∏–∫–∏ F1-macro

2. **–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª–∏–Ω —Ç–µ–∫—Å—Ç–æ–≤:**
   - –°–∏–ª—å–Ω–æ —Å–∫–æ—à–µ–Ω–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å –¥–ª–∏–Ω–Ω—ã–º —Ö–≤–æ—Å—Ç–æ–º
   - –ú–µ–¥–∏–∞–Ω–Ω–∞—è –¥–ª–∏–Ω–∞: ~488 —Å–∏–º–≤–æ–ª–æ–≤
   - –ï—Å—Ç—å –∞–Ω–æ–º–∞–ª—å–Ω–æ –¥–ª–∏–Ω–Ω—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è (–¥–æ 50K —Å–∏–º–≤–æ–ª–æ–≤)
   - –¢–µ–∫—Å—Ç—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –∏–º–µ—é—Ç —Ä–∞–∑–Ω—É—é —Å—Ä–µ–¥–Ω—é—é –¥–ª–∏–Ω—É

3. **–ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö:**
   - 1 –ø—Ä–æ–ø—É—Å–∫ –≤ –∫–æ–ª–æ–Ω–∫–µ description (0.002%)
   - –î—É–±–ª–∏–∫–∞—Ç—ã –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç, —Ç—Ä–µ–±—É—é—Ç —É–¥–∞–ª–µ–Ω–∏—è
   - –¢–µ–∫—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç HTML-—Ç–µ–≥–∏, URL, —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã

4. **–õ–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:**
   - –¢–µ–∫—Å—Ç—ã –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ
   - –ú–Ω–æ–≥–æ –ø–æ–≤—Ç–æ—Ä—è—é—â–∏—Ö—Å—è –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤—ã—Ö —Ñ—Ä–∞–∑
   - –í—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≤ –æ–ø–∏—Å–∞–Ω–∏—è—Ö

### –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è, –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–ª—è –¥–∞–Ω–Ω—ã—Ö

| –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ | –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ |
|---------------|-------------|
| –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ | –ò–∑–±–µ–∂–∞–Ω–∏–µ —É—Ç–µ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ |
| –£–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤ | –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –≤–ª–∏—è–Ω–∏–µ (1 –∑–∞–ø–∏—Å—å) |
| –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É | –£–Ω–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–æ–∫–µ–Ω–æ–≤ |
| –£–¥–∞–ª–µ–Ω–∏–µ HTML-—Ç–µ–≥–æ–≤ –∏ URL | –®—É–º –≤ –¥–∞–Ω–Ω—ã—Ö |
| –£–¥–∞–ª–µ–Ω–∏–µ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏ –∏ —Ü–∏—Ñ—Ä | –£–º–µ–Ω—å—à–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ |
| –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤ | –§–æ–∫—É—Å –Ω–∞ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã—Ö —Å–ª–æ–≤–∞—Ö |
| –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è | –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ñ–æ—Ä–º –æ–¥–Ω–æ–≥–æ —Å–ª–æ–≤–∞ |
| –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª–∏–Ω—ã —Ç–µ–∫—Å—Ç–∞ | –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤ (max_length) |

---

## üìä Baseline (`02_baseline.ipynb`)

### –ü–æ—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏

| –ú–æ–¥–µ–ª—å | –û–ø–∏—Å–∞–Ω–∏–µ | F1-macro | F1-weighted | Accuracy |
|--------|----------|----------|-------------|----------|
| **Linear SVM** | LinearSVC + TF-IDF | **0.9503** | **0.9510** | **0.9511** |
| **Logistic Regression** | TF-IDF + L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è | 0.9467 | 0.9469 | 0.9470 |
| **Naive Bayes** | MultinomialNB + TF-IDF | 0.9288 | 0.9284 | 0.9286 |
| **Random Forest** | 100 –¥–µ—Ä–µ–≤—å–µ–≤ + TF-IDF | 0.9229 | 0.9225 | 0.9227 |

**üèÜ –õ—É—á—à–∞—è baseline-–º–æ–¥–µ–ª—å:** Linear SVM (F1-macro = 0.9503)

### –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ (Baseline)

–ù–∞–∏–±–æ–ª—å—à–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—à–∏–±–æ–∫:
- Household ‚Üî Clothing (–ø–æ—Ö–æ–∂–∏–µ –æ–ø–∏—Å–∞–Ω–∏—è –¥–µ–∫–æ—Ä–∞ –∏ —Ç–µ–∫—Å—Ç–∏–ª—è)
- Electronics ‚Üî Household (–±—ã—Ç–æ–≤–∞—è —Ç–µ—Ö–Ω–∏–∫–∞ vs –¥–µ–∫–æ—Ä)

---

## üöÄ Improvements (`03_improvements.ipynb`)

### –ü—Ä–∏–º–µ–Ω—ë–Ω–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è

| ‚Ññ | –£–ª—É—á—à–µ–Ω–∏–µ | –û–ø–∏—Å–∞–Ω–∏–µ | F1-macro | Œî vs Baseline |
|---|-----------|----------|----------|---------------|
| 0 | **Baseline (Linear SVM)** | TF-IDF + LinearSVC | 0.9503 | ‚Äî |
| 1 | **–û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞** | –£–¥–∞–ª–µ–Ω–∏–µ HTML, URL, —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª–æ–≤ | 0.9586 | +0.0083 |
| 2 | **–õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è + —Å—Ç–æ–ø-—Å–ª–æ–≤–∞** | WordNetLemmatizer + NLTK stopwords | 0.9593 | +0.0090 |
| 3 | **N-–≥—Ä–∞–º–º—ã (1,2)** | TF-IDF —Å –±–∏–≥—Ä–∞–º–º–∞–º–∏ | 0.9621 | +0.0118 |
| 4 | **Class weights** | –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –≤–µ—Å–æ–≤ –∫–ª–∞—Å—Å–æ–≤ | 0.9630 | +0.0127 |
| 5 | **SMOTE** | –°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∞—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ | 0.9635 | +0.0132 |
| 6 | **–î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞** | Feature engineering | 0.9626 | +0.0123 |
| 7 | **Ensemble** | VotingClassifier (LR + SVM + NB) | 0.9634 | +0.0131 |
| 8 | **Chi-2 –æ—Ç–±–æ—Ä** | –û—Ç–±–æ—Ä 5000 –ª—É—á—à–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ | 0.9538 | +0.0035 |
| 9 | **Mutual Information** | –û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —á–µ—Ä–µ–∑ MI | 0.9533 | +0.0030 |
| 10 | **LightGBM** | –ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π –±—É—Å—Ç–∏–Ω–≥ | 0.9565 | +0.0062 |
| 11 | **Sentence-BERT** | –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ all-MiniLM-L6-v2 | 0.9423 | -0.0080 |
| 12 | **DistilBERT Fine-Tuning** | –ü—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–∞—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä-–º–æ–¥–µ–ª—å | **0.9727** | **+0.0224** |

### –ò—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

| –ú–æ–¥–µ–ª—å | F1-macro | Accuracy | –í—Ä–µ–º—è |
|--------|----------|----------|-------|
| Baseline (Linear SVM) | 0.9503 | 0.9511 | ~2 –º–∏–Ω |
| + –í—Å–µ —É–ª—É—á—à–µ–Ω–∏—è (LR) | 0.9630 | 0.9632 | ~5 –º–∏–Ω |
| **DistilBERT (fine-tuned)** | **0.9727** | **0.9729** | ~16 –º–∏–Ω |

### –£–ª—É—á—à–µ–Ω–∏—è, –Ω–µ –¥–∞–≤—à–∏–µ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø—Ä–∏—Ä–æ—Å—Ç–∞

| –£–ª—É—á—à–µ–Ω–∏–µ | Œî F1 | –û–±—ä—è—Å–Ω–µ–Ω–∏–µ |
|-----------|------|------------|
| Sentence-BERT —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ | -0.0080 | –ú–æ–¥–µ–ª—å all-MiniLM-L6-v2 —Ö—É–∂–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ |
| Mutual Information –æ—Ç–±–æ—Ä | +0.0030 | –ü–æ—Ç–µ—Ä—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø—Ä–∏ –æ—Ç–±–æ—Ä–µ |
| Chi-2 –æ—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ | +0.0035 | –°–ª–∏—à–∫–æ–º –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π –æ—Ç–±–æ—Ä |

---

## ‚öôÔ∏è Hyperparameter Tuning (`04_hyperparam_tuning.ipynb`)

### –ú–µ—Ç–æ–¥ —Ç—é–Ω–∏–Ω–≥–∞

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω **RandomizedSearchCV** —Å –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–µ–π (3-5 folds).

### –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç—é–Ω–∏–Ω–≥–∞

| –ú–æ–¥–µ–ª—å | F1-macro (CV) | F1-macro (Test) | Œî vs Baseline | –í—Ä–µ–º—è |
|--------|---------------|-----------------|---------------|-------|
| **Logistic Regression** | 0.9510 | **0.9717** | +0.0214 | 1.75 –º–∏–Ω |
| **Linear SVM** | 0.9572 | **0.9768** | **+0.0265** | 1.96 –º–∏–Ω |
| LightGBM (CPU) | 0.9395 | 0.9709 | +0.0206 | 25.70 –º–∏–Ω |
| DistilBERT (6 –∫–æ–º–±–∏–Ω–∞—Ü–∏–π) | 0.9644 | **0.9748** | +0.0245 | 34.92 –º–∏–Ω |

### üèÜ –ü–æ–±–µ–¥–∏—Ç–µ–ª–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º

| –ö–∞—Ç–µ–≥–æ—Ä–∏—è | –ú–æ–¥–µ–ª—å | F1-macro | –í—Ä–µ–º—è |
|-----------|--------|----------|-------|
| **ü•á –õ—É—á—à–∏–π F1** | **Linear SVM** | **0.9768** | 1.96 –º–∏–Ω |
| **ü•à 2-–µ –º–µ—Å—Ç–æ** | DistilBERT | 0.9748 | 34.92 –º–∏–Ω |
| **ü•â 3-–µ –º–µ—Å—Ç–æ** | Logistic Regression | 0.9717 | 1.75 –º–∏–Ω |

### –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã

#### Linear SVM (üèÜ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å)

```python
{
    'tfidf__max_features': 15000,
    'tfidf__ngram_range': (1, 1),
    'clf__C': 1.0
}
```

#### Logistic Regression

```python
{
    'tfidf__max_features': 10000,
    'tfidf__ngram_range': (1, 2),
    'clf__C': 5.0
}
```

#### DistilBERT

```python
{
    'learning_rate': 5e-5,
    'batch_size': 32,
    'num_epochs': 4
}
```

### –ü—Ä–∏—Ä–æ—Å—Ç –æ—Ç —Ç—é–Ω–∏–Ω–≥–∞

| –≠—Ç–∞–ø | F1-macro | Œî |
|------|----------|---|
| Baseline (Linear SVM) | 0.9503 | ‚Äî |
| –ü–æ—Å–ª–µ —Ç—é–Ω–∏–Ω–≥–∞ (Linear SVM) | **0.9768** | **+0.0265** |

---

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
ecommerce-classification/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ ecommerceDataset.csv      # –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py            # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
‚îÇ   ‚îú‚îÄ‚îÄ text_transformers.py      # –ö–∞—Å—Ç–æ–º–Ω—ã–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã —Ç–µ–∫—Å—Ç–∞
‚îÇ   ‚îú‚îÄ‚îÄ feature_selection.py      # –û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
‚îÇ   ‚îî‚îÄ‚îÄ embeddings.py             # –≠–º–±–µ–¥–¥–∏–Ω–≥–∏
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_eda.ipynb              # –†–∞–∑–≤–µ–¥–æ—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö
‚îÇ   ‚îú‚îÄ‚îÄ 02_baseline.ipynb         # –ë–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏
‚îÇ   ‚îú‚îÄ‚îÄ 03_improvements.ipynb     # –£–ª—É—á—à–µ–Ω–∏—è –∏ —Ñ–∏—á-–∏–Ω–∂–∏–Ω–∏—Ä–∏–Ω–≥
‚îÇ   ‚îî‚îÄ‚îÄ 04_hyperparam_tuning.ipynb # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
‚îú‚îÄ‚îÄ models/                        # –°–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
‚îÇ   ‚îú‚îÄ‚îÄ best_lr_pipeline.pkl
‚îÇ   ‚îú‚îÄ‚îÄ best_svm_pipeline.pkl
‚îÇ   ‚îú‚îÄ‚îÄ best_lgb_model.pkl
‚îÇ   ‚îî‚îÄ‚îÄ best_distilbert/
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

---

## üõ†Ô∏è –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –∑–∞–ø—É—Å–∫

```bash
# –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
git clone <repository-url>
cd ecommerce-classification

# –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
pip install -r requirements.txt

# –ó–∞–ø—É—Å–∫ Jupyter
jupyter notebook
```

### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏

```python
import pickle
from src.data_loader import load_data, preprocess_data

# –ó–∞–≥—Ä—É–∑–∫–∞ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ (Linear SVM)
with open('models/best_svm_pipeline.pkl', 'rb') as f:
    best_model = pickle.load(f)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
predictions = best_model.predict(['New product description...'])
print(predictions)

# –ò–ª–∏ –∑–∞–≥—Ä—É–∑–∫–∞ DistilBERT –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
from transformers import AutoModelForSequenceClassification, AutoTokenizer

model = AutoModelForSequenceClassification.from_pretrained('models/best_distilbert')
tokenizer = AutoTokenizer.from_pretrained('models/best_distilbert')
```

---

## üìà –ò—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

**üèÜ –§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å:** Linear SVM —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏

| –ú–µ—Ç—Ä–∏–∫–∞ | –ó–Ω–∞—á–µ–Ω–∏–µ |
|---------|----------|
| **F1-macro** | **0.9768** |
| Accuracy | 0.9770 |
| Precision-macro | 0.9765 |
| Recall-macro | 0.9771 |

### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å baseline

| –ú–æ–¥–µ–ª—å | F1-macro | –ü—Ä–∏—Ä–æ—Å—Ç |
|--------|----------|---------|
| Baseline (Linear SVM) | 0.9503 | ‚Äî |
| **Final (Linear SVM tuned)** | **0.9768** | **+2.65%** |

### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é

| –°—Ü–µ–Ω–∞—Ä–∏–π | –ú–æ–¥–µ–ª—å | –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ |
|----------|--------|-------------|
| **–ü—Ä–æ–¥–∞–∫—à–µ–Ω** | Linear SVM | –õ—É—á—à–∏–π F1 (0.9768) + –±—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ (1.96 –º–∏–Ω) + –±—ã—Å—Ç—Ä—ã–π –∏–Ω—Ñ–µ—Ä–µ–Ω—Å |
| **–ö–æ–º–ø—Ä–æ–º–∏—Å—Å** | Logistic Regression | –ü–æ—á—Ç–∏ —Ç–æ—Ç –∂–µ F1 (0.9717) + –µ—â—ë –±—ã—Å—Ç—Ä–µ–µ (1.55 –º–∏–Ω) + –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å |
| **–ú–∞–∫—Å–∏–º—É–º –∫–∞—á–µ—Å—Ç–≤–∞** | DistilBERT | –û—Ç–ª–∏—á–Ω—ã–π F1 (0.9743), –Ω–æ —Ç—Ä–µ–±—É–µ—Ç GPU –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –∏ 35 –º–∏–Ω –Ω–∞ —Ç—é–Ω–∏–Ω–≥ |


